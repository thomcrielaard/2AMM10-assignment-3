{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963690b2",
   "metadata": {
    "id": "963690b2"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a3_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8459f1",
   "metadata": {
    "id": "bd8459f1"
   },
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1:\n",
    "\n",
    "# Student 2:\n",
    "\n",
    "# Student 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde28458",
   "metadata": {
    "id": "dde28458"
   },
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {
    "id": "7d0580a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce00edc",
   "metadata": {
    "id": "8ce00edc"
   },
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_pickle(zipfile, fn):\n",
    "    return pickle.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {
    "id": "bb77a4be"
   },
   "outputs": [],
   "source": [
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/cwqGaS22KXgnXtg/download')\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "simulation_{train, valid, test} is stored as a list of simulations. \n",
    "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
    "\"\"\"\n",
    "simulation_train = load_pickle(data, 'data/train/simulation.pickle')  # 3.1 + 3.2\n",
    "simulation_valid = load_pickle(data, 'data/valid/simulation.pickle')  # 3.1 + 3.2\n",
    "simulation_test = load_pickle(data, 'data/test/simulation.pickle')  # 3.1 + 3.2\n",
    "\n",
    "\"\"\"\n",
    "charges_{train, valid, test} is stored as a list of simulation-charges. \n",
    "These charges are stored as numpy arrays of size (3,): One value for each charge.\n",
    "\"\"\"\n",
    "charges_train = load_pickle(data, 'data/train/charges.pickle')  # 3.1\n",
    "charges_valid = load_pickle(data, 'data/valid/charges.pickle')  # 3.1\n",
    "charges_test = load_pickle(data, 'data/test/charges.pickle')  # 3.1\n",
    "\n",
    "\"\"\"\n",
    "simulation_continued_{train, valid, test} is stored as a list of simulations. \n",
    "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
    "\"\"\"\n",
    "simulation_continued_train = load_pickle(data, 'data/train/simulation_continued.pickle')  # 3.2\n",
    "simulation_continued_valid = load_pickle(data, 'data/valid/simulation_continued.pickle')  # 3.2\n",
    "simulation_continued_test = load_pickle(data, 'data/test/simulation_continued.pickle')  # 3.2\n",
    "\n",
    "\"\"\"\n",
    "Note that the indices are shared throughout the different lists, e.g., for the 4th training simulation:\n",
    "simulation_train[3] contains its initial simulation\n",
    "charges_train[3] contains the charges associated with the simulation\n",
    "simulation_continued_train[3] contains the continuation of the simulation \n",
    "                --> simulation_continued_train[3][0] is the state after simulation_train[3][-1]\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a3438a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10a3438a",
    "outputId": "6035e76d-b4f9-4422-f58e-9e931083920c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "Task 3.1:\n",
      "800 train, 100 validation, 100 test simulations\n",
      "800 train, 100 validation, 100 test charge pairs\n",
      "\n",
      "Task 3.2:\n",
      "Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations\n",
      "We cut simulation_train down to the first 150 samples in simulation_train_task32\n",
      "150 train, 100 validation, 100 test simulations\n",
      "150 train, 100 validation, 100 test continuations\n",
      "\n",
      "For task 3.1, use:\n",
      "simulation_train + charges_train\n",
      "simulation_valid + charges_valid\n",
      "simulation_test + charges_test\n",
      "\n",
      "For task 3.2, use:\n",
      "simulation_train_task32 + simulation_continued_train\n",
      "simulation_valid + simulation_continued_valid\n",
      "simulation_test + simulation_continued_test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print('Task 3.1:')\n",
    "print(f'{len(simulation_train)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
    "print(f'{len(charges_train)} train, {len(charges_valid)} validation, {len(charges_test)} test charge pairs')\n",
    "print()\n",
    "\n",
    "print('Task 3.2:')\n",
    "print('Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations')\n",
    "print('We cut simulation_train down to the first 150 samples in simulation_train_task32')\n",
    "simulation_train_task32 = simulation_train[:150]\n",
    "print(f'{len(simulation_train_task32)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
    "print(f'{len(simulation_continued_train)} train, {len(simulation_continued_valid)} validation, {len(simulation_continued_test)} test continuations')\n",
    "\n",
    "print(f\"\"\"\n",
    "For task 3.1, use:\n",
    "{chr(10).join([\"simulation_{} + charges_{}\".format(t, t) for t in [\"train\", \"valid\", \"test\"]])}\n",
    "\n",
    "For task 3.2, use:\n",
    "{chr(10).join([\"simulation_{} + simulation_continued_{}\".format(*((t[0], t[1]) if isinstance(t, tuple) else (t, t))) for t in [(\"train_task32\", \"train\"), \"valid\", \"test\"]])}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfafdb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cfafdb3",
    "outputId": "cefc2526-dba6-489e-e726-38c61b696b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print some shapes:\n",
      "\n",
      "simulation_train[0].shape: (103, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[0].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[0].shape: (54, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n",
      "simulation_train[1].shape: (97, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[1].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[1].shape: (45, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n",
      "simulation_train[2].shape: (99, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[2].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[2].shape: (47, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Print some shapes:\\n')\n",
    "for i in range(3):\n",
    "    print('simulation_train[{}].shape:'.format(i), simulation_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
    "    print('charges_train[{}].shape:'.format(i), charges_train[i].shape, '-> charges for the simulation')\n",
    "    print('simulation_continued_train[{}].shape:'.format(i), simulation_continued_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
    "    print('----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9106543",
   "metadata": {
    "id": "f9106543"
   },
   "outputs": [],
   "source": [
    "def plot_example(x, x_gt=None, x_pred=None, fn=None):\n",
    "    charge_locations = np.array([[-1.53846154, -1.53846154],\n",
    "                                 [ 1.53846154, -1.53846154],\n",
    "                                 [ 0.        ,  1.53846154]])  # charge locations are fixed\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    cmap = matplotlib.cm.get_cmap('tab20')\n",
    "    plt.plot(x[:, 0], x[:, 1], color=cmap(0))\n",
    "    plt.plot(x[0, 0], x[0, 1], 'd', color=cmap(1))\n",
    "    fig.set_size_inches(5, 5)\n",
    "    for charge in charge_locations:\n",
    "        plt.plot(charge[0], charge[1], 'd', color='black')\n",
    "    if x_gt is not None:\n",
    "        plt.plot(x_gt[:, 0], x_gt[:, 1], color='red', linewidth=.5)\n",
    "    if x_pred is not None:\n",
    "        plt.plot(x_pred[:, 0], x_pred[:, 1], color='green', linestyle='--')\n",
    "    if fn is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28681a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "d28681a6",
    "outputId": "9b44cd40-5d2e-4ba9-b165-4023f183b135"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charges are [-0.1399828  -0.60077349 -0.94377978]\n"
     ]
    }
   ],
   "source": [
    "test_idx = np.random.randint(150)\n",
    "plot_example(simulation_train[test_idx], simulation_continued_train[test_idx])\n",
    "print(f'Charges are {charges_train[test_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883762b1",
   "metadata": {
    "id": "883762b1"
   },
   "source": [
    "# Task 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ddabe",
   "metadata": {
    "id": "4c1ddabe"
   },
   "source": [
    "## Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9df856",
   "metadata": {
    "id": "bd9df856"
   },
   "outputs": [],
   "source": [
    "# The inputs for this model would be the location of each particle (p1, p2, p3, p4), the initial charges for p2, p3, and p4\n",
    "# The output is a set of charges at every t, for the maximum\n",
    "\n",
    "# 1. Sort the input sequences by length <- Saving this for optimization later\n",
    "# 2. Pad the input sequences to the maximum length per batch, thus minimizing the amount of padding in the input\n",
    "  # This is 110\n",
    "# 3. Put the input sequences into a dataloader, for shuffling and batching\n",
    "\n",
    "# Maybe sorting isn't even necessary, because the sequences are not that long to begin with.\n",
    "# Padding with 0s is usually done, but this could reduce accuracy for longer sequences, as most examples will have 0 at the end.\n",
    "# I think we can combat this by not calculating loss for the sequence past its usefulness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd9b7c1",
   "metadata": {
    "id": "7dd9b7c1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ec1e03a",
   "metadata": {
    "id": "4ec1e03a"
   },
   "outputs": [],
   "source": [
    "simulation_train_tensor_no_padding = torch.zeros(800, 90, 1, 2)\n",
    "simulation_train_tensor_with_padding = torch.zeros(800, 110, 1, 2)\n",
    "simulation_train_no_nothing = []\n",
    "for i in range(800):\n",
    "  tensor = torch.Tensor(simulation_train[i])\n",
    "  simulation_train_no_nothing.append(tensor)\n",
    "  simulation_train_tensor_with_padding[i] = F.pad(tensor, (0,0,0,110 - tensor.shape[0])).unsqueeze(dim=1)\n",
    "  simulation_train_tensor_no_padding[i] = tensor[-90:, :].unsqueeze(dim=1)\n",
    "\n",
    "simulation_eval = torch.zeros(100, 90, 1, 2)\n",
    "simulation_eval_no_nothing = []\n",
    "for i in range(100):\n",
    "  tensor = torch.Tensor(simulation_valid[i])\n",
    "  simulation_eval_no_nothing.append(tensor)\n",
    "  simulation_eval[i] = tensor[-90:, :].unsqueeze(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "lyraAkKykAbz",
   "metadata": {
    "id": "lyraAkKykAbz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_tensor, output_tensor):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.output_tensor = output_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_tensor[idx], self.output_tensor[idx].unsqueeze(dim=0)\n",
    "\n",
    "train_dataset = CustomDataset(simulation_train_tensor_no_padding, torch.Tensor(charges_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "train_dataset_padding = CustomDataset(simulation_train_tensor_with_padding, torch.Tensor(charges_train))\n",
    "train_dataloader_padding = DataLoader(train_dataset_padding, batch_size=1, shuffle=True)\n",
    "\n",
    "eval_dataset = CustomDataset(simulation_eval, torch.Tensor(charges_valid))\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "train_no_nothing = CustomDataset(simulation_train_no_nothing, torch.Tensor(charges_train))\n",
    "train_no_nothing_dataloader = DataLoader(train_no_nothing, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8853f6",
   "metadata": {
    "id": "cc8853f6"
   },
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "UR1mwYsYl7hW",
   "metadata": {
    "id": "UR1mwYsYl7hW"
   },
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Define LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Define a fully connected layer\n",
    "        self.fc =  nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Forward through lstm layer\n",
    "        _, (h_n, c_n) = self.lstm(inputs)\n",
    "        \n",
    "        # Forward through dense layer\n",
    "        hidden = self.fc(h_n)\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b5aa6",
   "metadata": {
    "id": "d62b5aa6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192ee18",
   "metadata": {
    "id": "5192ee18"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e443b7f",
   "metadata": {
    "id": "0e443b7f"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a5b0aca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5a5b0aca",
    "outputId": "564ad6ca-90d9-404c-e4bd-f87af2be7472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, mean training loss: 0.11029312943312107, mean eval loss: 0.11314823975553737\n",
      "epoch: 2, mean training loss: 0.09320741240793723, mean eval loss: 0.10194721930194646\n",
      "epoch: 3, mean training loss: 0.08723646827260381, mean eval loss: 0.09752160009928047\n",
      "epoch: 4, mean training loss: 0.08497529038467291, mean eval loss: 0.09561986138112843\n",
      "epoch: 5, mean training loss: 0.08396821469741553, mean eval loss: 0.09467147509567439\n",
      "epoch: 6, mean training loss: 0.08339997639603097, mean eval loss: 0.09404403899796307\n",
      "epoch: 7, mean training loss: 0.08301568349954323, mean eval loss: 0.09366343430243433\n",
      "epoch: 8, mean training loss: 0.08271338882404962, mean eval loss: 0.0934128056652844\n",
      "epoch: 9, mean training loss: 0.08245536872491357, mean eval loss: 0.09310033956542611\n",
      "epoch: 10, mean training loss: 0.08222692799201468, mean eval loss: 0.09293420737609268\n",
      "epoch: 11, mean training loss: 0.08202659208633122, mean eval loss: 0.09279684133827687\n",
      "epoch: 12, mean training loss: 0.0818450350688363, mean eval loss: 0.09258991342037916\n",
      "epoch: 13, mean training loss: 0.08168330599961336, mean eval loss: 0.09245776088908314\n",
      "epoch: 14, mean training loss: 0.08152838710826472, mean eval loss: 0.09242377273738384\n",
      "epoch: 15, mean training loss: 0.08139877019304549, mean eval loss: 0.0922873593866825\n",
      "epoch: 16, mean training loss: 0.0812723828695016, mean eval loss: 0.092190717831254\n",
      "epoch: 17, mean training loss: 0.08116361861728365, mean eval loss: 0.09208552572876215\n",
      "epoch: 18, mean training loss: 0.0810578533433727, mean eval loss: 0.09191851139068603\n",
      "epoch: 19, mean training loss: 0.08095954592732596, mean eval loss: 0.09189774174243212\n",
      "epoch: 20, mean training loss: 0.08087031772724003, mean eval loss: 0.09181871715933085\n",
      "epoch: 21, mean training loss: 0.08079079869174166, mean eval loss: 0.09172269498929381\n",
      "epoch: 22, mean training loss: 0.08071129829288111, mean eval loss: 0.09164719399064779\n",
      "epoch: 23, mean training loss: 0.08063741935780853, mean eval loss: 0.09160940365865827\n",
      "epoch: 24, mean training loss: 0.08057230328427976, mean eval loss: 0.09150151176378131\n",
      "epoch: 25, mean training loss: 0.08050456661745557, mean eval loss: 0.09145351551473141\n",
      "epoch: 26, mean training loss: 0.08044546498669661, mean eval loss: 0.09138439008966089\n",
      "epoch: 27, mean training loss: 0.08038675599280395, mean eval loss: 0.09134918931871652\n",
      "epoch: 28, mean training loss: 0.08033238313320908, mean eval loss: 0.0912589304894209\n",
      "epoch: 29, mean training loss: 0.08027691550931194, mean eval loss: 0.09121240915730595\n",
      "epoch: 30, mean training loss: 0.08022379389687558, mean eval loss: 0.09125297393649817\n",
      "epoch: 31, mean training loss: 0.0801808870685636, mean eval loss: 0.09120103966444731\n",
      "epoch: 32, mean training loss: 0.08013467577897244, mean eval loss: 0.09110739024356007\n",
      "epoch: 33, mean training loss: 0.08008981314400444, mean eval loss: 0.09105472343042492\n",
      "epoch: 34, mean training loss: 0.08004595783699188, mean eval loss: 0.09096829243004322\n",
      "epoch: 35, mean training loss: 0.08000649623529171, mean eval loss: 0.09093874910846353\n",
      "epoch: 36, mean training loss: 0.07996543934597866, mean eval loss: 0.09089941922575236\n",
      "epoch: 37, mean training loss: 0.07992294286479591, mean eval loss: 0.09083645183593035\n",
      "epoch: 38, mean training loss: 0.07988645806995918, mean eval loss: 0.09081799659878015\n",
      "epoch: 39, mean training loss: 0.07985080089449184, mean eval loss: 0.09076824735850096\n",
      "epoch: 40, mean training loss: 0.07980959525215439, mean eval loss: 0.09078029971569776\n",
      "epoch: 41, mean training loss: 0.0797778007222223, mean eval loss: 0.09072186980396509\n",
      "epoch: 42, mean training loss: 0.07974387372465572, mean eval loss: 0.0906213496439159\n",
      "epoch: 43, mean training loss: 0.07971199086197885, mean eval loss: 0.09059469671919942\n",
      "epoch: 44, mean training loss: 0.07967387448647059, mean eval loss: 0.09062307462096214\n",
      "epoch: 45, mean training loss: 0.079645908678649, mean eval loss: 0.09060844074934721\n",
      "epoch: 46, mean training loss: 0.07961439756167238, mean eval loss: 0.0905366831459105\n",
      "epoch: 47, mean training loss: 0.07958419372909703, mean eval loss: 0.09046527601778508\n",
      "epoch: 48, mean training loss: 0.07955331997916801, mean eval loss: 0.0905175101198256\n",
      "epoch: 49, mean training loss: 0.07952409766003257, mean eval loss: 0.09045585399493575\n",
      "epoch: 50, mean training loss: 0.07949392121023266, mean eval loss: 0.0904153092764318\n",
      "epoch: 51, mean training loss: 0.07946350315294694, mean eval loss: 0.09043106138706207\n",
      "epoch: 52, mean training loss: 0.07943520277302013, mean eval loss: 0.09044770799577236\n",
      "epoch: 53, mean training loss: 0.07940635903942166, mean eval loss: 0.09040185336023569\n",
      "epoch: 54, mean training loss: 0.07938103843436693, mean eval loss: 0.09037715641781688\n",
      "epoch: 55, mean training loss: 0.07935119829737232, mean eval loss: 0.09025754729285836\n",
      "epoch: 56, mean training loss: 0.07932578997540986, mean eval loss: 0.09021916650235653\n",
      "epoch: 57, mean training loss: 0.07929782497230917, mean eval loss: 0.09024742895737291\n",
      "epoch: 58, mean training loss: 0.07927384816925041, mean eval loss: 0.09019302604719996\n",
      "epoch: 59, mean training loss: 0.0792381127801491, mean eval loss: 0.0901324619166553\n",
      "epoch: 60, mean training loss: 0.07922048836859176, mean eval loss: 0.09013409856706858\n",
      "epoch: 61, mean training loss: 0.07919689857022603, mean eval loss: 0.09010710764676333\n",
      "epoch: 62, mean training loss: 0.07916596435476095, mean eval loss: 0.09000686619430781\n",
      "epoch: 63, mean training loss: 0.07914648122736252, mean eval loss: 0.09000827325507998\n",
      "epoch: 64, mean training loss: 0.07911149228501017, mean eval loss: 0.08992359910160302\n",
      "epoch: 65, mean training loss: 0.07909409221319948, mean eval loss: 0.09000624345615506\n",
      "epoch: 66, mean training loss: 0.07907393410336226, mean eval loss: 0.08995956173166633\n",
      "epoch: 67, mean training loss: 0.07904889430326875, mean eval loss: 0.08992186626419425\n",
      "epoch: 68, mean training loss: 0.0790273744557635, mean eval loss: 0.08991127219051123\n",
      "epoch: 69, mean training loss: 0.07900211743966792, mean eval loss: 0.08988231357187032\n",
      "epoch: 70, mean training loss: 0.07897911524385563, mean eval loss: 0.08982961684465408\n",
      "epoch: 71, mean training loss: 0.07895047747166245, mean eval loss: 0.08983087867498397\n",
      "epoch: 72, mean training loss: 0.07893487457928132, mean eval loss: 0.0897860019095242\n",
      "epoch: 73, mean training loss: 0.07891038490779465, mean eval loss: 0.08975223872810602\n",
      "epoch: 74, mean training loss: 0.07888913905801019, mean eval loss: 0.08973638117313384\n",
      "epoch: 75, mean training loss: 0.07886366640028428, mean eval loss: 0.0896812811307609\n",
      "epoch: 76, mean training loss: 0.07884327098669018, mean eval loss: 0.08970524271950125\n",
      "epoch: 77, mean training loss: 0.07882469695119652, mean eval loss: 0.08968199765309691\n",
      "epoch: 78, mean training loss: 0.07880259692406981, mean eval loss: 0.08963466376066208\n",
      "epoch: 79, mean training loss: 0.07878181490901624, mean eval loss: 0.0895945711247623\n",
      "epoch: 80, mean training loss: 0.07875530943929335, mean eval loss: 0.089599479008466\n",
      "epoch: 81, mean training loss: 0.07873725382174598, mean eval loss: 0.08959574004635215\n",
      "epoch: 82, mean training loss: 0.07871510941404267, mean eval loss: 0.08949352873489261\n",
      "epoch: 83, mean training loss: 0.07869648338266416, mean eval loss: 0.08948264200240373\n",
      "epoch: 84, mean training loss: 0.07867409604339627, mean eval loss: 0.08943341640755534\n",
      "epoch: 85, mean training loss: 0.07865351121829008, mean eval loss: 0.08938624080270528\n",
      "epoch: 86, mean training loss: 0.07863279507335391, mean eval loss: 0.08943140596151351\n",
      "epoch: 87, mean training loss: 0.07861485142726451, mean eval loss: 0.08942558500915766\n",
      "epoch: 88, mean training loss: 0.07859631279556197, mean eval loss: 0.08939200984314084\n",
      "epoch: 89, mean training loss: 0.07857600254821591, mean eval loss: 0.08941257199272513\n",
      "epoch: 90, mean training loss: 0.07855713851211477, mean eval loss: 0.08934315970167518\n",
      "epoch: 91, mean training loss: 0.07853115104400786, mean eval loss: 0.08935771098360419\n",
      "epoch: 92, mean training loss: 0.07851811990694842, mean eval loss: 0.08935616223141551\n",
      "epoch: 93, mean training loss: 0.07849733245471725, mean eval loss: 0.08929157393053173\n",
      "epoch: 94, mean training loss: 0.07847810611172462, mean eval loss: 0.08917661800980568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 95, mean training loss: 0.0784580984862987, mean eval loss: 0.08922459052875638\n",
      "epoch: 96, mean training loss: 0.07844096012340743, mean eval loss: 0.08921032262966037\n",
      "epoch: 97, mean training loss: 0.07842462011263705, mean eval loss: 0.08916405458003282\n",
      "epoch: 98, mean training loss: 0.07840342698444147, mean eval loss: 0.08915203662589193\n",
      "epoch: 99, mean training loss: 0.07838644132643821, mean eval loss: 0.08912455091252923\n",
      "epoch: 100, mean training loss: 0.07835982818578487, mean eval loss: 0.08920559981837868\n"
     ]
    }
   ],
   "source": [
    "# Define runtime device\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Hyper parameter and model definition\n",
    "input_dim = 2\n",
    "hidden_dim = 3\n",
    "lstm = LSTM1(input_dim, hidden_dim).to(dev)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(lstm.parameters(), lr = learning_rate)\n",
    "num_epochs = 100\n",
    "dataloader = train_no_nothing_dataloader\n",
    "\n",
    "lossPerEpoch = np.empty((num_epochs, 1))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  total_loss = 0\n",
    "  total_eval_loss = 0\n",
    "  \n",
    "\n",
    "  # Set in train mode\n",
    "  lstm.train()\n",
    "\n",
    "  # Train the model\n",
    "  iterator = iter(dataloader)\n",
    "  for i in range(len(iterator)):\n",
    "    x, y = next(iterator)\n",
    "    \n",
    "    # Move to GPU\n",
    "    x = x.to(dev)\n",
    "    y = y.to(dev)\n",
    "\n",
    "    # Propagate forward\n",
    "    hidden = lstm(x[0])\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(hidden[0], y[0])\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    # Backward propagate\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  \n",
    "  \n",
    "  # Set in eval mode\n",
    "  lstm.eval()\n",
    "\n",
    "  # Evaluate loss on verification set\n",
    "  eval_iterator = iter(eval_dataloader)\n",
    "  for i in range(len(eval_iterator)):\n",
    "    with torch.no_grad():\n",
    "      x, y = next(eval_iterator)\n",
    "    \n",
    "      # Move to GPU\n",
    "      x = x.to(dev)\n",
    "      y = y.to(dev)\n",
    "    \n",
    "      # Propagate forward\n",
    "      hidden = lstm(x[0])\n",
    "    \n",
    "      # Compute loss\n",
    "      loss = criterion(hidden[0], y[0])\n",
    "      total_eval_loss += loss.item()\n",
    "        \n",
    "  average_training_loss = total_loss / len(iterator)\n",
    "  average_eval_loss = total_eval_loss / len(eval_iterator)\n",
    "    \n",
    "  lossPerEpoch[epoch] = average_training_loss\n",
    "\n",
    "  print(f'epoch: {epoch+1}, mean training loss: {average_training_loss}, mean eval loss: {average_eval_loss}')\n",
    "\n",
    "  \n",
    "\n",
    "#TODO: Might need to zero out the hidden state of lstm, but maybe not\n",
    "#TODO: Experiment with num_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58348edd",
   "metadata": {
    "id": "58348edd"
   },
   "outputs": [],
   "source": [
    "# without padding :epoch: 25, mean training loss: 0.08195400983095169, mean eval loss: 0.09817712453918324\n",
    "# epoch: 100, mean training loss: 0.0861954316496849, mean eval loss: 0.10278522804379463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b3ea3",
   "metadata": {
    "id": "176b3ea3"
   },
   "outputs": [],
   "source": [
    "# without any cutting : epoch: 56, mean training loss: 0.07555700838565826, mean eval loss: 0.08626986091025174\n",
    "# With linear layer: epoch: 56, mean training loss: 0.07898687571287155, mean eval loss: 0.08656595157459378\n",
    "# With reLU + linear layer: epoch: 56, mean training loss: 0.08114010095596313, mean eval loss: 0.09263360679149628"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da139d5b",
   "metadata": {
    "id": "da139d5b"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ebed03ba",
   "metadata": {
    "id": "ebed03ba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), lossPerEpoch, \"b-\", label=\"Loss\")\n",
    "#plt.plot(range(num_epochs), stdPerEpoch, \"g-\", label=\"Standard Deviation\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Observed loss\")\n",
    "plt.title(\"Model training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17af7ec3",
   "metadata": {
    "id": "17af7ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted charges: [-0.39694968 -0.5663664  -0.44165167], Actual charges: [-0.38935432 -0.48996845 -0.08618085]\n",
      "Predicted charges: [-0.53655976 -0.49205464 -0.60467416], Actual charges: [-0.67374104 -0.25783342 -0.5131491 ]\n",
      "Predicted charges: [-0.4977952  -0.49702752 -0.5471723 ], Actual charges: [-0.641466   -0.91733015 -0.8782985 ]\n",
      "Predicted charges: [-0.5237041 -0.4599792 -0.5796321], Actual charges: [-0.16873121 -0.1138682  -0.8036771 ]\n",
      "Predicted charges: [-0.4344493  -0.50372976 -0.47537228], Actual charges: [-0.26474082 -0.2182094  -0.07958777]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# number of example predictions\n",
    "nrExamplePredictions = 5\n",
    "\n",
    "# Set model to eval mode\n",
    "lstm.eval()\n",
    "\n",
    "for examplePrediction in range(nrExamplePredictions):\n",
    "    # Get a random index\n",
    "    index = random.choice(range(len(simulation_test)))\n",
    "    \n",
    "    # Get corresponding tensors\n",
    "    particlePositions = torch.tensor(simulation_test[index]).type(torch.FloatTensor).to(dev)\n",
    "    particleCharges = torch.tensor(charges_test[index]).type(torch.FloatTensor).to(dev)\n",
    "    \n",
    "    # Forward propagate the particle positions through the model\n",
    "    with torch.no_grad():\n",
    "        predictedCharges = lstm(particlePositions)\n",
    "    \n",
    "    # Print results\n",
    "    print(f'Predicted charges: {predictedCharges[0].cpu().numpy()}, Actual charges: {particleCharges.cpu().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3422e",
   "metadata": {
    "id": "43a3422e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a59808b",
   "metadata": {
    "id": "9a59808b"
   },
   "source": [
    "# Task 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a855d",
   "metadata": {
    "id": "f64a855d"
   },
   "source": [
    "## Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b935865",
   "metadata": {
    "id": "5b935865"
   },
   "outputs": [],
   "source": [
    "#todo\n",
    "# Let's add the static input at every call of the model, or design it in a way that has a seperate method for the static data (per simulation) for 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec19a8d",
   "metadata": {
    "id": "0ec19a8d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f189d19",
   "metadata": {
    "id": "8f189d19"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867aabb3",
   "metadata": {
    "id": "867aabb3"
   },
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe2739",
   "metadata": {
    "id": "36fe2739"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b1ca2",
   "metadata": {
    "id": "f80b1ca2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf2800",
   "metadata": {
    "id": "fdbf2800"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826fae3f",
   "metadata": {
    "id": "826fae3f"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fce95",
   "metadata": {
    "id": "db3fce95"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddb47d",
   "metadata": {
    "id": "41ddb47d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee069fc",
   "metadata": {
    "id": "4ee069fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87278a2",
   "metadata": {
    "id": "c87278a2"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb6137",
   "metadata": {
    "id": "2cbb6137"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6f4b7",
   "metadata": {
    "id": "2cf6f4b7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c10d8",
   "metadata": {
    "id": "736c10d8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "f64a855d",
    "867aabb3",
    "826fae3f",
    "c87278a2"
   ],
   "name": "Copy of Copy of a3_skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
