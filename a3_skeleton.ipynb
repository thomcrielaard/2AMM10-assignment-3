{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "963690b2",
      "metadata": {
        "id": "963690b2"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a3_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8459f1",
      "metadata": {
        "id": "bd8459f1"
      },
      "source": [
        "# Group Number:\n",
        "\n",
        "# Student 1:\n",
        "\n",
        "# Student 2:\n",
        "\n",
        "# Student 3:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dde28458",
      "metadata": {
        "id": "dde28458"
      },
      "source": [
        "# Downloading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import requests\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ce00edc",
      "metadata": {
        "id": "8ce00edc"
      },
      "outputs": [],
      "source": [
        "def load_zip(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    zipf = ZipFile(io.BytesIO(response.content))\n",
        "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
        "\n",
        "def load_pickle(zipfile, fn):\n",
        "    return pickle.load(io.BytesIO(zipfile[fn]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb77a4be",
      "metadata": {
        "id": "bb77a4be"
      },
      "outputs": [],
      "source": [
        "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/cwqGaS22KXgnXtg/download')\n",
        "\n",
        "    \n",
        "\"\"\"\n",
        "simulation_{train, valid, test} is stored as a list of simulations. \n",
        "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
        "\"\"\"\n",
        "simulation_train = load_pickle(data, 'data/train/simulation.pickle')  # 3.1 + 3.2\n",
        "simulation_valid = load_pickle(data, 'data/valid/simulation.pickle')  # 3.1 + 3.2\n",
        "simulation_test = load_pickle(data, 'data/test/simulation.pickle')  # 3.1 + 3.2\n",
        "\n",
        "\"\"\"\n",
        "charges_{train, valid, test} is stored as a list of simulation-charges. \n",
        "These charges are stored as numpy arrays of size (3,): One value for each charge.\n",
        "\"\"\"\n",
        "charges_train = load_pickle(data, 'data/train/charges.pickle')  # 3.1\n",
        "charges_valid = load_pickle(data, 'data/valid/charges.pickle')  # 3.1\n",
        "charges_test = load_pickle(data, 'data/test/charges.pickle')  # 3.1\n",
        "\n",
        "\"\"\"\n",
        "simulation_continued_{train, valid, test} is stored as a list of simulations. \n",
        "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
        "\"\"\"\n",
        "simulation_continued_train = load_pickle(data, 'data/train/simulation_continued.pickle')  # 3.2\n",
        "simulation_continued_valid = load_pickle(data, 'data/valid/simulation_continued.pickle')  # 3.2\n",
        "simulation_continued_test = load_pickle(data, 'data/test/simulation_continued.pickle')  # 3.2\n",
        "\n",
        "\"\"\"\n",
        "Note that the indices are shared throughout the different lists, e.g., for the 4th training simulation:\n",
        "simulation_train[3] contains its initial simulation\n",
        "charges_train[3] contains the charges associated with the simulation\n",
        "simulation_continued_train[3] contains the continuation of the simulation \n",
        "                --> simulation_continued_train[3][0] is the state after simulation_train[3][-1]\n",
        "\"\"\"\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a3438a",
      "metadata": {
        "id": "10a3438a",
        "outputId": "6035e76d-b4f9-4422-f58e-9e931083920c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overview of no. datapoints:\n",
            "\n",
            "Task 3.1:\n",
            "800 train, 100 validation, 100 test simulations\n",
            "800 train, 100 validation, 100 test charge pairs\n",
            "\n",
            "Task 3.2:\n",
            "Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations\n",
            "We cut simulation_train down to the first 150 samples in simulation_train_task32\n",
            "150 train, 100 validation, 100 test simulations\n",
            "150 train, 100 validation, 100 test continuations\n",
            "\n",
            "For task 3.1, use:\n",
            "simulation_train + charges_train\n",
            "simulation_valid + charges_valid\n",
            "simulation_test + charges_test\n",
            "\n",
            "For task 3.2, use:\n",
            "simulation_train_task32 + simulation_continued_train\n",
            "simulation_valid + simulation_continued_valid\n",
            "simulation_test + simulation_continued_test\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Overview of no. datapoints:\\n')\n",
        "\n",
        "print('Task 3.1:')\n",
        "print(f'{len(simulation_train)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
        "print(f'{len(charges_train)} train, {len(charges_valid)} validation, {len(charges_test)} test charge pairs')\n",
        "print()\n",
        "\n",
        "print('Task 3.2:')\n",
        "print('Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations')\n",
        "print('We cut simulation_train down to the first 150 samples in simulation_train_task32')\n",
        "simulation_train_task32 = simulation_train[:150]\n",
        "print(f'{len(simulation_train_task32)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
        "print(f'{len(simulation_continued_train)} train, {len(simulation_continued_valid)} validation, {len(simulation_continued_test)} test continuations')\n",
        "\n",
        "print(f\"\"\"\n",
        "For task 3.1, use:\n",
        "{chr(10).join([\"simulation_{} + charges_{}\".format(t, t) for t in [\"train\", \"valid\", \"test\"]])}\n",
        "\n",
        "For task 3.2, use:\n",
        "{chr(10).join([\"simulation_{} + simulation_continued_{}\".format(*((t[0], t[1]) if isinstance(t, tuple) else (t, t))) for t in [(\"train_task32\", \"train\"), \"valid\", \"test\"]])}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cfafdb3",
      "metadata": {
        "id": "3cfafdb3",
        "outputId": "cefc2526-dba6-489e-e726-38c61b696b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Print some shapes:\n",
            "\n",
            "simulation_train[0].shape: (103, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[0].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[0].shape: (54, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n",
            "simulation_train[1].shape: (97, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[1].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[1].shape: (45, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n",
            "simulation_train[2].shape: (99, 2) -> (t, 2), (x, y) at every t)\n",
            "charges_train[2].shape: (3,) -> charges for the simulation\n",
            "simulation_continued_train[2].shape: (47, 2) -> (t, 2), (x, y) at every t)\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Print some shapes:\\n')\n",
        "for i in range(3):\n",
        "    print('simulation_train[{}].shape:'.format(i), simulation_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
        "    print('charges_train[{}].shape:'.format(i), charges_train[i].shape, '-> charges for the simulation')\n",
        "    print('simulation_continued_train[{}].shape:'.format(i), simulation_continued_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
        "    print('----\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9106543",
      "metadata": {
        "id": "f9106543"
      },
      "outputs": [],
      "source": [
        "def plot_example(x, x_gt=None, x_pred=None, fn=None):\n",
        "    charge_locations = np.array([[-1.53846154, -1.53846154],\n",
        "                                 [ 1.53846154, -1.53846154],\n",
        "                                 [ 0.        ,  1.53846154]])  # charge locations are fixed\n",
        "    fig = plt.figure()\n",
        "    axes = plt.gca()\n",
        "    axes.set_xlim([-5., 5.])\n",
        "    axes.set_ylim([-5., 5.])\n",
        "    cmap = matplotlib.cm.get_cmap('tab20')\n",
        "    plt.plot(x[:, 0], x[:, 1], color=cmap(0))\n",
        "    plt.plot(x[0, 0], x[0, 1], 'd', color=cmap(1))\n",
        "    fig.set_size_inches(5, 5)\n",
        "    for charge in charge_locations:\n",
        "        plt.plot(charge[0], charge[1], 'd', color='black')\n",
        "    if x_gt is not None:\n",
        "        plt.plot(x_gt[:, 0], x_gt[:, 1], color='red', linewidth=.5)\n",
        "    if x_pred is not None:\n",
        "        plt.plot(x_pred[:, 0], x_pred[:, 1], color='green', linestyle='--')\n",
        "    if fn is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28681a6",
      "metadata": {
        "id": "d28681a6",
        "outputId": "9b44cd40-5d2e-4ba9-b165-4023f183b135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charges are [-0.31872102 -0.3226225  -0.72394261]\n"
          ]
        }
      ],
      "source": [
        "test_idx = np.random.randint(150)\n",
        "plot_example(simulation_train[test_idx], simulation_continued_train[test_idx])\n",
        "print(f'Charges are {charges_train[test_idx]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883762b1",
      "metadata": {
        "id": "883762b1"
      },
      "source": [
        "# Task 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c1ddabe",
      "metadata": {
        "id": "4c1ddabe"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9df856",
      "metadata": {
        "id": "bd9df856"
      },
      "outputs": [],
      "source": [
        "# The inputs for this model would be the location of each particle (p1, p2, p3, p4), the initial charges for p2, p3, and p4\n",
        "# The output is a set of charges at every t, for the maximum\n",
        "\n",
        "# 1. Sort the input sequences by length <- Saving this for optimization later\n",
        "# 2. Pad the input sequences to the maximum length per batch, thus minimizing the amount of padding in the input\n",
        "  # This is 110\n",
        "# 3. Put the input sequences into a dataloader, for shuffling and batching\n",
        "\n",
        "# Maybe sorting isn't even necessary, because the sequences are not that long to begin with.\n",
        "# Padding with 0s is usually done, but this could reduce accuracy for longer sequences, as most examples will have 0 at the end.\n",
        "# I think we can combat this by not calculating loss for the sequence past its usefulness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd9b7c1",
      "metadata": {
        "id": "7dd9b7c1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ec1e03a",
      "metadata": {
        "id": "4ec1e03a"
      },
      "outputs": [],
      "source": [
        "simulation_train_tensor_no_padding = torch.zeros(800, 90, 1, 2)\n",
        "simulation_train_tensor_with_padding = torch.zeros(800, 110, 1, 2)\n",
        "simulation_train_no_nothing = []\n",
        "for i in range(800):\n",
        "  tensor = torch.Tensor(simulation_train[i])\n",
        "  simulation_train_no_nothing.append(tensor)\n",
        "  simulation_train_tensor_with_padding[i] = F.pad(tensor, (0,0,0,110 - tensor.shape[0])).unsqueeze(dim=1)\n",
        "  simulation_train_tensor_no_padding[i] = tensor[-90:, :].unsqueeze(dim=1)\n",
        "\n",
        "simulation_eval = torch.zeros(100, 90, 1, 2)\n",
        "simulation_eval_no_nothing = []\n",
        "for i in range(100):\n",
        "  tensor = torch.Tensor(simulation_valid[i])\n",
        "  simulation_eval_no_nothing.append(tensor)\n",
        "  simulation_eval[i] = tensor[-90:, :].unsqueeze(dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_tensor, output_tensor):\n",
        "        self.input_tensor = input_tensor\n",
        "        self.output_tensor = output_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_tensor)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_tensor[idx], self.output_tensor[idx].unsqueeze(dim=0)\n",
        "\n",
        "train_dataset = CustomDataset(simulation_train_tensor_no_padding, torch.Tensor(charges_train))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "train_dataset_padding = CustomDataset(simulation_train_tensor_with_padding, torch.Tensor(charges_train))\n",
        "train_dataloader_padding = DataLoader(train_dataset_padding, batch_size=1, shuffle=True)\n",
        "\n",
        "eval_dataset = CustomDataset(simulation_eval, torch.Tensor(charges_valid))\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "train_no_nothing = CustomDataset(simulation_train_no_nothing, torch.Tensor(charges_train))\n",
        "train_no_nothing_dataloader = DataLoader(train_no_nothing, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "lyraAkKykAbz"
      },
      "id": "lyraAkKykAbz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cc8853f6",
      "metadata": {
        "id": "cc8853f6"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = nn.LSTM(2, 3)"
      ],
      "metadata": {
        "id": "UR1mwYsYl7hW"
      },
      "id": "UR1mwYsYl7hW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62b5aa6",
      "metadata": {
        "id": "d62b5aa6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5192ee18",
      "metadata": {
        "id": "5192ee18"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e443b7f",
      "metadata": {
        "id": "0e443b7f"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5b0aca",
      "metadata": {
        "id": "5a5b0aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "564ad6ca-90d9-404c-e4bd-f87af2be7472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, mean training loss: 0.37331584095954895, mean eval loss: 0.39068005861714483\n",
            "epoch: 2, mean training loss: 0.34235718846321106, mean eval loss: 0.36143234703689814\n",
            "epoch: 3, mean training loss: 0.3184298872947693, mean eval loss: 0.3378955808375031\n",
            "epoch: 4, mean training loss: 0.29894477128982544, mean eval loss: 0.31826680799014867\n",
            "epoch: 5, mean training loss: 0.282471626996994, mean eval loss: 0.3014277027919888\n",
            "epoch: 6, mean training loss: 0.26814764738082886, mean eval loss: 0.2866262689884752\n",
            "epoch: 7, mean training loss: 0.2553998827934265, mean eval loss: 0.2733670192817226\n",
            "epoch: 8, mean training loss: 0.2438637763261795, mean eval loss: 0.2613366729998961\n",
            "epoch: 9, mean training loss: 0.23327606916427612, mean eval loss: 0.25026264287531375\n",
            "epoch: 10, mean training loss: 0.22344940900802612, mean eval loss: 0.2399813184980303\n",
            "epoch: 11, mean training loss: 0.21425312757492065, mean eval loss: 0.23035775105468928\n",
            "epoch: 12, mean training loss: 0.2055920958518982, mean eval loss: 0.22130163912661374\n",
            "epoch: 13, mean training loss: 0.1973998248577118, mean eval loss: 0.2127557122800499\n",
            "epoch: 14, mean training loss: 0.18961986899375916, mean eval loss: 0.20465717618353665\n",
            "epoch: 15, mean training loss: 0.18220309913158417, mean eval loss: 0.196950742052868\n",
            "epoch: 16, mean training loss: 0.17509549856185913, mean eval loss: 0.18957009530626237\n",
            "epoch: 17, mean training loss: 0.16826681792736053, mean eval loss: 0.1825042037013918\n",
            "epoch: 18, mean training loss: 0.1616889238357544, mean eval loss: 0.17570159932598473\n",
            "epoch: 19, mean training loss: 0.15533529222011566, mean eval loss: 0.16913727244362234\n",
            "epoch: 20, mean training loss: 0.14919337630271912, mean eval loss: 0.16278914749622345\n",
            "epoch: 21, mean training loss: 0.14326375722885132, mean eval loss: 0.15665534785948693\n",
            "epoch: 22, mean training loss: 0.13755916059017181, mean eval loss: 0.15075098177418111\n",
            "epoch: 23, mean training loss: 0.13209453225135803, mean eval loss: 0.14507873257622123\n",
            "epoch: 24, mean training loss: 0.12689174711704254, mean eval loss: 0.1396642703562975\n",
            "epoch: 25, mean training loss: 0.12197817862033844, mean eval loss: 0.1345487785153091\n",
            "epoch: 26, mean training loss: 0.1173645555973053, mean eval loss: 0.12972766396589577\n",
            "epoch: 27, mean training loss: 0.11305883526802063, mean eval loss: 0.12522827971726655\n",
            "epoch: 28, mean training loss: 0.10906177759170532, mean eval loss: 0.12104929356370121\n",
            "epoch: 29, mean training loss: 0.1053571030497551, mean eval loss: 0.11717748815193772\n",
            "epoch: 30, mean training loss: 0.10192018747329712, mean eval loss: 0.11359425446949899\n",
            "epoch: 31, mean training loss: 0.09872906655073166, mean eval loss: 0.11027898037573322\n",
            "epoch: 32, mean training loss: 0.09574972838163376, mean eval loss: 0.10720327454386279\n",
            "epoch: 33, mean training loss: 0.09296710044145584, mean eval loss: 0.10437491777352989\n",
            "epoch: 34, mean training loss: 0.09036775678396225, mean eval loss: 0.10176643272629007\n",
            "epoch: 35, mean training loss: 0.08794950693845749, mean eval loss: 0.09939853064250201\n",
            "epoch: 36, mean training loss: 0.08573855459690094, mean eval loss: 0.09726731477770954\n",
            "epoch: 37, mean training loss: 0.08375540375709534, mean eval loss: 0.09539537468925119\n",
            "epoch: 38, mean training loss: 0.08203258365392685, mean eval loss: 0.09378967529162764\n",
            "epoch: 39, mean training loss: 0.08059757947921753, mean eval loss: 0.09247291969135403\n",
            "epoch: 40, mean training loss: 0.07946008443832397, mean eval loss: 0.0913964750804007\n",
            "epoch: 41, mean training loss: 0.0785810574889183, mean eval loss: 0.0905225676856935\n",
            "epoch: 42, mean training loss: 0.07791619747877121, mean eval loss: 0.08981491897255182\n",
            "epoch: 43, mean training loss: 0.07742533832788467, mean eval loss: 0.08924607791006565\n",
            "epoch: 44, mean training loss: 0.07706959545612335, mean eval loss: 0.08878274908289313\n",
            "epoch: 45, mean training loss: 0.07679194957017899, mean eval loss: 0.08839374694041907\n",
            "epoch: 46, mean training loss: 0.07657776027917862, mean eval loss: 0.08805615457706154\n",
            "epoch: 47, mean training loss: 0.07640491425991058, mean eval loss: 0.0877650798857212\n",
            "epoch: 48, mean training loss: 0.07626372575759888, mean eval loss: 0.0875088020041585\n",
            "epoch: 49, mean training loss: 0.07614161819219589, mean eval loss: 0.08728724914602935\n",
            "epoch: 50, mean training loss: 0.07603379338979721, mean eval loss: 0.0870919446926564\n",
            "epoch: 51, mean training loss: 0.07593841105699539, mean eval loss: 0.08693070476874709\n",
            "epoch: 52, mean training loss: 0.07585220038890839, mean eval loss: 0.08676072351634502\n",
            "epoch: 53, mean training loss: 0.07577107101678848, mean eval loss: 0.08662326483987272\n",
            "epoch: 54, mean training loss: 0.07569553703069687, mean eval loss: 0.08649175552651286\n",
            "epoch: 55, mean training loss: 0.07562245428562164, mean eval loss: 0.08637780942954124\n",
            "epoch: 56, mean training loss: 0.07555700838565826, mean eval loss: 0.08626986091025174\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-959166d6aec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "criterion = nn.MSELoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(lstm.parameters(), lr = learning_rate)\n",
        "num_epochs = 100\n",
        "dataloader = train_no_nothing_dataloader\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  # Set in train mode\n",
        "  lstm.train()\n",
        "\n",
        "  # Train the model\n",
        "  iterator = iter(dataloader)\n",
        "  for i in range(len(iterator)):\n",
        "    x, y = next(iterator)\n",
        "    \n",
        "    output, hidden = lstm(x[0])\n",
        "    loss = criterion(hidden[0], y[0])\n",
        "    total_loss += loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  \n",
        "\n",
        "  lstm.eval()\n",
        "  total_eval_loss = 0\n",
        "  eval_iterator = iter(eval_dataloader)\n",
        "  for i in range(len(eval_iterator)):\n",
        "    with torch.no_grad():\n",
        "      x, y = next(eval_iterator)\n",
        "      output, hidden = lstm(x[0])\n",
        "      loss = criterion(hidden[0], y)\n",
        "      total_eval_loss += loss.item()\n",
        "  average_loss = total_eval_loss / len(eval_iterator)\n",
        "  print(f'epoch: {epoch+1}, mean training loss: {total_loss/len(iterator)}, mean eval loss: {average_loss}')\n",
        "\n",
        "  \n",
        "\n",
        "# TODO: Might need to zero out the hidden state of lstm, but maybe not\n",
        "#TODO: Experiment with num_layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58348edd",
      "metadata": {
        "id": "58348edd"
      },
      "outputs": [],
      "source": [
        "# without padding :epoch: 25, mean training loss: 0.08195400983095169, mean eval loss: 0.09817712453918324\n",
        "# epoch: 100, mean training loss: 0.0861954316496849, mean eval loss: 0.10278522804379463"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176b3ea3",
      "metadata": {
        "id": "176b3ea3"
      },
      "outputs": [],
      "source": [
        "# without any cutting : epoch: 56, mean training loss: 0.07555700838565826, mean eval loss: 0.08626986091025174"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da139d5b",
      "metadata": {
        "id": "da139d5b"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebed03ba",
      "metadata": {
        "id": "ebed03ba"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17af7ec3",
      "metadata": {
        "id": "17af7ec3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a3422e",
      "metadata": {
        "id": "43a3422e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a59808b",
      "metadata": {
        "id": "9a59808b"
      },
      "source": [
        "# Task 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64a855d",
      "metadata": {
        "id": "f64a855d"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b935865",
      "metadata": {
        "id": "5b935865"
      },
      "outputs": [],
      "source": [
        "#todo\n",
        "# Let's add the static input at every call of the model, or design it in a way that has a seperate method for the static data (per simulation) for 3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ec19a8d",
      "metadata": {
        "id": "0ec19a8d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f189d19",
      "metadata": {
        "id": "8f189d19"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867aabb3",
      "metadata": {
        "id": "867aabb3"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36fe2739",
      "metadata": {
        "id": "36fe2739"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80b1ca2",
      "metadata": {
        "id": "f80b1ca2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdbf2800",
      "metadata": {
        "id": "fdbf2800"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826fae3f",
      "metadata": {
        "id": "826fae3f"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db3fce95",
      "metadata": {
        "id": "db3fce95"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ddb47d",
      "metadata": {
        "id": "41ddb47d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee069fc",
      "metadata": {
        "id": "4ee069fc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87278a2",
      "metadata": {
        "id": "c87278a2"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cbb6137",
      "metadata": {
        "id": "2cbb6137"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf6f4b7",
      "metadata": {
        "id": "2cf6f4b7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "736c10d8",
      "metadata": {
        "id": "736c10d8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Copy of Copy of a3_skeleton.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f64a855d",
        "867aabb3",
        "826fae3f",
        "c87278a2"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}